"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[1053],{4862:(e,t,o)=>{o.r(t),o.d(t,{assets:()=>c,contentTitle:()=>i,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>p});var s=o(5773),n=(o(7378),o(5318)),m=o(6538);const a='import { ConversationChain } from "langchain/chains";\nimport { ChatOpenAI } from "langchain/chat_models";\nimport {\n  ChatPromptTemplate,\n  HumanMessagePromptTemplate,\n  SystemMessagePromptTemplate,\n  MessagesPlaceholder,\n} from "langchain/prompts";\nimport { BufferMemory } from "langchain/memory";\n\nexport const run = async () => {\n  const chat = new ChatOpenAI({ temperature: 0 });\n\n  const chatPrompt = ChatPromptTemplate.fromPromptMessages([\n    SystemMessagePromptTemplate.fromTemplate(\n      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know."\n    ),\n    new MessagesPlaceholder("history"),\n    HumanMessagePromptTemplate.fromTemplate("{input}"),\n  ]);\n\n  const chain = new ConversationChain({\n    memory: new BufferMemory({ returnMessages: true, memoryKey: "history" }),\n    prompt: chatPrompt,\n    llm: chat,\n  });\n\n  const response = await chain.call({\n    input: "hi! whats up?",\n  });\n\n  console.log(response);\n};\n',r={hide_table_of_contents:!0},i="Memory",l={unversionedId:"modules/memory/examples/buffer_memory_chat",id:"modules/memory/examples/buffer_memory_chat",title:"Memory",description:"This example covers how to use chat specific memory classes with chat models.",source:"@site/docs/modules/memory/examples/buffer_memory_chat.mdx",sourceDirName:"modules/memory/examples",slug:"/modules/memory/examples/buffer_memory_chat",permalink:"/langchainjs/docs/modules/memory/examples/buffer_memory_chat",draft:!1,editUrl:"https://github.com/hwchase17/langchainjs/docs/modules/memory/examples/buffer_memory_chat.mdx",tags:[],version:"current",frontMatter:{hide_table_of_contents:!0},sidebar:"sidebar",previous:{title:"Buffer Memory",permalink:"/langchainjs/docs/modules/memory/examples/buffer_memory"},next:{title:"Buffer Window Memory",permalink:"/langchainjs/docs/modules/memory/examples/buffer_window_memory"}},c={},p=[],h={toc:p},u="wrapper";function d(e){let{components:t,...o}=e;return(0,n.kt)(u,(0,s.Z)({},h,o,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"memory"},"Memory"),(0,n.kt)("p",null,"This example covers how to use chat specific memory classes with chat models.\nThe key thing to notice is that setting ",(0,n.kt)("inlineCode",{parentName:"p"},"returnMessages: true")," makes the memory return a list of chat messages instead of a string."),(0,n.kt)(m.Z,{language:"typescript",mdxType:"CodeBlock"},a))}d.isMDXComponent=!0}}]);