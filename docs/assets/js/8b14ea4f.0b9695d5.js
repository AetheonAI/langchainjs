"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[9103],{9500:(n,t,a)=>{a.r(t),a.d(t,{assets:()=>m,contentTitle:()=>r,default:()=>u,frontMatter:()=>l,metadata:()=>c,toc:()=>p});var e=a(5773),o=(a(7378),a(5318)),s=a(6538);const i='import { OpenAI } from "langchain/llms";\nimport {\n  ChatPromptTemplate,\n  HumanMessagePromptTemplate,\n  PromptTemplate,\n  SystemMessagePromptTemplate,\n} from "langchain/prompts";\nimport { LLMChain } from "langchain/chains";\nimport { ChatOpenAI } from "langchain/chat_models";\n\nexport const run = async () => {\n  // We can construct an LLMChain from a PromptTemplate and an LLM.\n  const model = new OpenAI({ temperature: 0 });\n  const template = "What is a good name for a company that makes {product}?";\n  const prompt = new PromptTemplate({ template, inputVariables: ["product"] });\n  const chainA = new LLMChain({ llm: model, prompt });\n  const resA = await chainA.call({ product: "colorful socks" });\n  // The result is an object with a `text` property.\n  console.log({ resA });\n  // { resA: { text: \'\\n\\nSocktastic!\' } }\n\n  // Since the LLMChain is a single-input, single-output chain, we can also call it with `run`.\n  // This takes in a string and returns the `text` property.\n  const resA2 = await chainA.run("colorful socks");\n  console.log({ resA2 });\n  // { resA2: \'\\n\\nSocktastic!\' }\n\n  // We can also construct an LLMChain from a ChatPromptTemplate and a chat model.\n  const chat = new ChatOpenAI({ temperature: 0 });\n  const chatPrompt = ChatPromptTemplate.fromPromptMessages([\n    SystemMessagePromptTemplate.fromTemplate(\n      "You are a helpful assistant that translates {input_language} to {output_language}."\n    ),\n    HumanMessagePromptTemplate.fromTemplate("{text}"),\n  ]);\n  const chainB = new LLMChain({\n    prompt: chatPrompt,\n    llm: chat,\n  });\n  const resB = await chainB.call({\n    input_language: "English",\n    output_language: "French",\n    text: "I love programming.",\n  });\n  console.log({ resB });\n  // { resB: { text: "J\'adore la programmation." } }\n};\n',l={hide_table_of_contents:!0,sidebar_label:"LLM Chain"},r="Getting Started: LLMChain",c={unversionedId:"modules/chains/llmchain/index",id:"modules/chains/llmchain/index",title:"Getting Started: LLMChain",description:"Conceptual Guide",source:"@site/docs/modules/chains/llmchain/index.mdx",sourceDirName:"modules/chains/llmchain",slug:"/modules/chains/llmchain/",permalink:"/langchainjs/docs/modules/chains/llmchain/",draft:!1,editUrl:"https://github.com/hwchase17/langchainjs/docs/modules/chains/llmchain/index.mdx",tags:[],version:"current",frontMatter:{hide_table_of_contents:!0,sidebar_label:"LLM Chain"},sidebar:"sidebar",previous:{title:"RetrievalQAChain",permalink:"/langchainjs/docs/modules/chains/index_related_chains/retrieval_qa"},next:{title:"Other Chains",permalink:"/langchainjs/docs/modules/chains/other_chains/"}},m={},p=[],h={toc:p},d="wrapper";function u(n){let{components:t,...a}=n;return(0,o.kt)(d,(0,e.Z)({},h,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"getting-started-llmchain"},"Getting Started: LLMChain"),(0,o.kt)("admonition",{type:"info"},(0,o.kt)("p",{parentName:"admonition"},(0,o.kt)("a",{parentName:"p",href:"https://docs.langchain.com/docs/components/chains/llm-chain"},"Conceptual Guide"))),(0,o.kt)("p",null,"An ",(0,o.kt)("inlineCode",{parentName:"p"},"LLMChain")," is a simple chain that adds some functionality around language models. It is used widely throughout LangChain, including in other chains and agents."),(0,o.kt)("p",null,"An ",(0,o.kt)("inlineCode",{parentName:"p"},"LLMChain")," consists of a ",(0,o.kt)("inlineCode",{parentName:"p"},"PromptTemplate")," and a language model (either and LLM or chat model)."),(0,o.kt)("p",null,"We can construct an LLMChain which takes user input, formats it with a PromptTemplate, and then passes the formatted response to an LLM:"),(0,o.kt)(s.Z,{language:"typescript",mdxType:"CodeBlock"},i))}u.isMDXComponent=!0}}]);