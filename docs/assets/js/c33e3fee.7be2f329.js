"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7427],{1876:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>m,contentTitle:()=>r,default:()=>h,frontMatter:()=>i,metadata:()=>c,toc:()=>d});var s=n(5773),o=(n(7378),n(5318)),a=n(6538);const l='import { OpenAI } from "langchain";\nimport { initializeAgentExecutor } from "langchain/agents";\nimport { SerpAPI, Calculator } from "langchain/tools";\n\nexport const run = async () => {\n  const model = new OpenAI({ temperature: 0 });\n  const tools = [new SerpAPI(), new Calculator()];\n\n  const executor = await initializeAgentExecutor(\n    tools,\n    model,\n    "zero-shot-react-description",\n    true\n  );\n  console.log("Loaded agent.");\n\n  const input = `Who is Olivia Wilde\'s boyfriend? What is his current age raised to the 0.23 power?`;\n\n  console.log(`Executing with input "${input}"...`);\n\n  const result = await executor.call({ input });\n\n  console.log(`Got output ${result.output}`);\n};\n',i={hide_table_of_contents:!0,sidebar_position:1},r="MRKL Agent for LLMs",c={unversionedId:"modules/agents/agents/examples/llm_mrkl",id:"modules/agents/agents/examples/llm_mrkl",title:"MRKL Agent for LLMs",description:"This example covers how to use an agent that uses the ReAct Framework (based on the descriptions of tools) to decide what action to take. This agent is optimized to be used with LLMs. If you want to use it with a chat model, try the Chat MRKL Agent.",source:"@site/docs/modules/agents/agents/examples/llm_mrkl.mdx",sourceDirName:"modules/agents/agents/examples",slug:"/modules/agents/agents/examples/llm_mrkl",permalink:"/langchainjs/docs/modules/agents/agents/examples/llm_mrkl",draft:!1,editUrl:"https://github.com/hwchase17/langchainjs/docs/modules/agents/agents/examples/llm_mrkl.mdx",tags:[],version:"current",sidebarPosition:1,frontMatter:{hide_table_of_contents:!0,sidebar_position:1},sidebar:"sidebar",previous:{title:"Examples",permalink:"/langchainjs/docs/modules/agents/agents/examples/"},next:{title:"MRKL Agent for Chat Models",permalink:"/langchainjs/docs/modules/agents/agents/examples/chat_mrkl"}},m={},d=[],u={toc:d},p="wrapper";function h(e){let{components:t,...n}=e;return(0,o.kt)(p,(0,s.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"mrkl-agent-for-llms"},"MRKL Agent for LLMs"),(0,o.kt)("p",null,"This example covers how to use an agent that uses the ReAct Framework (based on the descriptions of tools) to decide what action to take. This agent is optimized to be used with LLMs. If you want to use it with a chat model, try the ",(0,o.kt)("a",{parentName:"p",href:"./chat_mrkl"},"Chat MRKL Agent"),"."),(0,o.kt)(a.Z,{language:"typescript",mdxType:"CodeBlock"},l))}h.isMDXComponent=!0}}]);