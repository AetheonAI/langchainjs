"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[3497],{5318:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>f});var i=n(7378);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,i)}return n}function a(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,i,r=function(e,t){if(null==e)return{};var n,i,r={},o=Object.keys(e);for(i=0;i<o.length;i++)n=o[i],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(i=0;i<o.length;i++)n=o[i],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=i.createContext({}),d=function(e){var t=i.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):a(a({},t),e)),n},u=function(e){var t=d(e.components);return i.createElement(s.Provider,{value:t},e.children)},m="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},p=i.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),m=d(n),p=r,f=m["".concat(s,".").concat(p)]||m[p]||c[p]||o;return n?i.createElement(f,a(a({ref:t},u),{},{components:n})):i.createElement(f,a({ref:t},u))}));function f(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,a=new Array(o);a[0]=p;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[m]="string"==typeof e?e:r,a[1]=l;for(var d=2;d<o;d++)a[d]=n[d];return i.createElement.apply(null,a)}return i.createElement.apply(null,n)}p.displayName="MDXCreateElement"},4121:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>a,default:()=>c,frontMatter:()=>o,metadata:()=>l,toc:()=>d});var i=n(5773),r=(n(7378),n(5318));const o={sidebar_label:"Additional Functionality"},a="Additional Functionality: Embeddings",l={unversionedId:"modules/models/embeddings/additional_functionality",id:"modules/models/embeddings/additional_functionality",title:"Additional Functionality: Embeddings",description:"We offer a number of additional features for chat models. In the examples below, we'll be using the ChatOpenAI model.",source:"@site/docs/modules/models/embeddings/additional_functionality.mdx",sourceDirName:"modules/models/embeddings",slug:"/modules/models/embeddings/additional_functionality",permalink:"/langchainjs/docs/modules/models/embeddings/additional_functionality",draft:!1,editUrl:"https://github.com/hwchase17/langchainjs/docs/modules/models/embeddings/additional_functionality.mdx",tags:[],version:"current",frontMatter:{sidebar_label:"Additional Functionality"},sidebar:"sidebar",previous:{title:"Integrations",permalink:"/langchainjs/docs/modules/models/embeddings/integrations"},next:{title:"LLMs",permalink:"/langchainjs/docs/modules/models/llms/"}},s={},d=[{value:"Dealing with Rate Limits",id:"dealing-with-rate-limits",level:2},{value:"Dealing with API Errors",id:"dealing-with-api-errors",level:2}],u={toc:d},m="wrapper";function c(e){let{components:t,...n}=e;return(0,r.kt)(m,(0,i.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"additional-functionality-embeddings"},"Additional Functionality: Embeddings"),(0,r.kt)("p",null,"We offer a number of additional features for chat models. In the examples below, we'll be using the ",(0,r.kt)("inlineCode",{parentName:"p"},"ChatOpenAI")," model."),(0,r.kt)("h2",{id:"dealing-with-rate-limits"},"Dealing with Rate Limits"),(0,r.kt)("p",null,"Some providers have rate limits. If you exceed the rate limit, you'll get an error. To help you deal with this, LangChain provides a ",(0,r.kt)("inlineCode",{parentName:"p"},"maxConcurrency")," option when instantiating an Embeddings model. This option allows you to specify the maximum number of concurrent requests you want to make to the provider. If you exceed this number, LangChain will automatically queue up your requests to be sent as previous requests complete."),(0,r.kt)("p",null,"For example, if you set ",(0,r.kt)("inlineCode",{parentName:"p"},"maxConcurrency: 5"),", then LangChain will only send 5 requests to the provider at a time. If you send 10 requests, the first 5 will be sent immediately, and the next 5 will be queued up. Once one of the first 5 requests completes, the next request in the queue will be sent."),(0,r.kt)("p",null,"To use this feature, simply pass ",(0,r.kt)("inlineCode",{parentName:"p"},"maxConcurrency: <number>")," when you instantiate the LLM. For example:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-typescript"},'import { OpenAIEmbeddings } from "langchain/embeddings";\n\nconst model = new OpenAIEmbeddings({ maxConcurrency: 5 });\n')),(0,r.kt)("h2",{id:"dealing-with-api-errors"},"Dealing with API Errors"),(0,r.kt)("p",null,"If the model provider returns an error from their API, by default LangChain will retry up to 6 times on an exponential backoff. This enables error recovery without any additional effort from you. If you want to change this behavior, you can pass a ",(0,r.kt)("inlineCode",{parentName:"p"},"maxRetries")," option when you instantiate the model. For example:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-typescript"},'import { OpenAIEmbeddings } from "langchain/embeddings";\n\nconst model = new OpenAIEmbeddings({ maxRetries: 10 });\n')))}c.isMDXComponent=!0}}]);