"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[6712],{2794:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>r,default:()=>p,frontMatter:()=>l,metadata:()=>c,toc:()=>m});var o=n(5773),s=(n(7378),n(5318)),a=n(6538);const i='import { ChatOpenAI } from "langchain/chat_models";\nimport { initializeAgentExecutor } from "langchain/agents";\nimport { SerpAPI, Calculator } from "langchain/tools";\n\nexport const run = async () => {\n  const model = new ChatOpenAI({ temperature: 0 });\n  const tools = [new SerpAPI(), new Calculator()];\n\n  const executor = await initializeAgentExecutor(\n    tools,\n    model,\n    "chat-zero-shot-react-description"\n  );\n  console.log("Loaded agent.");\n\n  const input = `Who is Olivia Wilde\'s boyfriend? What is his current age raised to the 0.23 power?`;\n\n  console.log(`Executing with input "${input}"...`);\n\n  const result = await executor.call({ input });\n\n  console.log(`Got output ${result.output}`);\n\n  console.log(\n    `Got intermediate steps ${JSON.stringify(\n      result.intermediateSteps,\n      null,\n      2\n    )}`\n  );\n};\n',l={hide_table_of_contents:!0,sidebar_position:2},r="MRKL Agent for Chat Models",c={unversionedId:"modules/agents/agents/examples/chat_mrkl",id:"modules/agents/agents/examples/chat_mrkl",title:"MRKL Agent for Chat Models",description:"This example covers how to use an agent that uses the ReAct Framework (based on the descriptions of tools) to decide what action to take. This agent is optimized to be used with Chat Models. If you want to use it with an LLM, you can use the LLM MRKL Agent instead.",source:"@site/docs/modules/agents/agents/examples/chat_mrkl.mdx",sourceDirName:"modules/agents/agents/examples",slug:"/modules/agents/agents/examples/chat_mrkl",permalink:"/langchainjs/docs/modules/agents/agents/examples/chat_mrkl",draft:!1,editUrl:"https://github.com/hwchase17/langchainjs/docs/modules/agents/agents/examples/chat_mrkl.mdx",tags:[],version:"current",sidebarPosition:2,frontMatter:{hide_table_of_contents:!0,sidebar_position:2},sidebar:"sidebar",previous:{title:"MRKL Agent for LLMs",permalink:"/langchainjs/docs/modules/agents/agents/examples/llm_mrkl"},next:{title:"Conversational Agent",permalink:"/langchainjs/docs/modules/agents/agents/examples/conversational_agent"}},d={},m=[],u={toc:m},h="wrapper";function p(e){let{components:t,...n}=e;return(0,s.kt)(h,(0,o.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,s.kt)("h1",{id:"mrkl-agent-for-chat-models"},"MRKL Agent for Chat Models"),(0,s.kt)("p",null,"This example covers how to use an agent that uses the ReAct Framework (based on the descriptions of tools) to decide what action to take. This agent is optimized to be used with Chat Models. If you want to use it with an LLM, you can use the ",(0,s.kt)("a",{parentName:"p",href:"./llm_mrkl"},"LLM MRKL Agent")," instead."),(0,s.kt)(a.Z,{language:"typescript",mdxType:"CodeBlock"},i))}p.isMDXComponent=!0}}]);