"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[16],{1565:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>c,default:()=>p,frontMatter:()=>o,metadata:()=>d,toc:()=>h});var a=n(5773),i=(n(7378),n(5318));const r='import { OpenAI } from "langchain/llms";\nimport { RetrievalQAChain } from "langchain/chains";\nimport { HNSWLib } from "langchain/vectorstores";\nimport { OpenAIEmbeddings } from "langchain/embeddings";\nimport { RecursiveCharacterTextSplitter } from "langchain/text_splitter";\nimport * as fs from "fs";\n\nexport const run = async () => {\n  // Initialize the LLM to use to answer the question.\n  const model = new OpenAI({});\n  const text = fs.readFileSync("state_of_the_union.txt", "utf8");\n  const textSplitter = new RecursiveCharacterTextSplitter({ chunkSize: 1000 });\n  const docs = await textSplitter.createDocuments([text]);\n\n  // Create a vector store from the documents.\n  const vectorStore = await HNSWLib.fromDocuments(docs, new OpenAIEmbeddings());\n\n  // Create a chain that uses the OpenAI LLM and HNSWLib vector store.\n  const chain = RetrievalQAChain.fromLLM(model, vectorStore.asRetriever());\n  const res = await chain.call({\n    input_documents: docs,\n    query: "What did the president say about Justice Breyer?",\n  });\n  console.log({ res });\n  /*\n  {\n    res: {\n      text: \'The president said that Justice Breyer was an Army veteran, Constitutional scholar,\n      and retiring Justice of the United States Supreme Court and thanked him for his service.\'\n    }\n  }\n  */\n};\n';var s=n(6538);const o={},c="RetrievalQAChain",d={unversionedId:"modules/chains/index_related_chains/retrieval_qa",id:"modules/chains/index_related_chains/retrieval_qa",title:"RetrievalQAChain",description:"The RetrievalQAChain is a chain that combines a Retriever and a QA chain (described above). It is used to retrieve documents from a Retriever and then use a QA chain to answer a question based on the retrieved documents.",source:"@site/docs/modules/chains/index_related_chains/retrieval_qa.mdx",sourceDirName:"modules/chains/index_related_chains",slug:"/modules/chains/index_related_chains/retrieval_qa",permalink:"/langchainjs/docs/modules/chains/index_related_chains/retrieval_qa",draft:!1,editUrl:"https://github.com/hwchase17/langchainjs/docs/modules/chains/index_related_chains/retrieval_qa.mdx",tags:[],version:"current",frontMatter:{},sidebar:"sidebar",previous:{title:"Document QA Chains",permalink:"/langchainjs/docs/modules/chains/index_related_chains/document_qa"},next:{title:"LLM Chain",permalink:"/langchainjs/docs/modules/chains/llmchain/"}},l={},h=[],m={toc:h},u="wrapper";function p(e){let{components:t,...n}=e;return(0,i.kt)(u,(0,a.Z)({},m,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"retrievalqachain"},(0,i.kt)("inlineCode",{parentName:"h1"},"RetrievalQAChain")),(0,i.kt)("p",null,"The ",(0,i.kt)("inlineCode",{parentName:"p"},"RetrievalQAChain")," is a chain that combines a ",(0,i.kt)("inlineCode",{parentName:"p"},"Retriever")," and a QA chain (described above). It is used to retrieve documents from a ",(0,i.kt)("inlineCode",{parentName:"p"},"Retriever")," and then use a ",(0,i.kt)("inlineCode",{parentName:"p"},"QA")," chain to answer a question based on the retrieved documents."),(0,i.kt)("p",null,"In the below example, we are using a ",(0,i.kt)("inlineCode",{parentName:"p"},"VectorStore")," as the ",(0,i.kt)("inlineCode",{parentName:"p"},"Retriever"),". By default, the ",(0,i.kt)("inlineCode",{parentName:"p"},"StuffDocumentsChain")," is used as the ",(0,i.kt)("inlineCode",{parentName:"p"},"QA")," chain."),(0,i.kt)(s.Z,{language:"typescript",mdxType:"CodeBlock"},r))}p.isMDXComponent=!0}}]);