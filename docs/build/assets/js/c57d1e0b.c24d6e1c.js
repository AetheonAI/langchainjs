"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[2906],{5318:(t,e,n)=>{n.d(e,{Zo:()=>u,kt:()=>m});var o=n(7378);function r(t,e,n){return e in t?Object.defineProperty(t,e,{value:n,enumerable:!0,configurable:!0,writable:!0}):t[e]=n,t}function a(t,e){var n=Object.keys(t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(t);e&&(o=o.filter((function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable}))),n.push.apply(n,o)}return n}function s(t){for(var e=1;e<arguments.length;e++){var n=null!=arguments[e]?arguments[e]:{};e%2?a(Object(n),!0).forEach((function(e){r(t,e,n[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(t,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(e){Object.defineProperty(t,e,Object.getOwnPropertyDescriptor(n,e))}))}return t}function i(t,e){if(null==t)return{};var n,o,r=function(t,e){if(null==t)return{};var n,o,r={},a=Object.keys(t);for(o=0;o<a.length;o++)n=a[o],e.indexOf(n)>=0||(r[n]=t[n]);return r}(t,e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(t);for(o=0;o<a.length;o++)n=a[o],e.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(t,n)&&(r[n]=t[n])}return r}var c=o.createContext({}),l=function(t){var e=o.useContext(c),n=e;return t&&(n="function"==typeof t?t(e):s(s({},e),t)),n},u=function(t){var e=l(t.components);return o.createElement(c.Provider,{value:e},t.children)},p="mdxType",h={inlineCode:"code",wrapper:function(t){var e=t.children;return o.createElement(o.Fragment,{},e)}},d=o.forwardRef((function(t,e){var n=t.components,r=t.mdxType,a=t.originalType,c=t.parentName,u=i(t,["components","mdxType","originalType","parentName"]),p=l(n),d=r,m=p["".concat(c,".").concat(d)]||p[d]||h[d]||a;return n?o.createElement(m,s(s({ref:e},u),{},{components:n})):o.createElement(m,s({ref:e},u))}));function m(t,e){var n=arguments,r=e&&e.mdxType;if("string"==typeof t||r){var a=n.length,s=new Array(a);s[0]=d;var i={};for(var c in e)hasOwnProperty.call(e,c)&&(i[c]=e[c]);i.originalType=t,i[p]="string"==typeof t?t:r,s[1]=i;for(var l=2;l<a;l++)s[l]=n[l];return o.createElement.apply(null,s)}return o.createElement.apply(null,n)}d.displayName="MDXCreateElement"},7916:(t,e,n)=>{n.r(e),n.d(e,{assets:()=>c,contentTitle:()=>s,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>l});var o=n(5773),r=(n(7378),n(5318));const a={},s="Agents with Vector Stores",i={unversionedId:"modules/agents/tools/agents_with_vectorstores",id:"modules/agents/tools/agents_with_vectorstores",title:"Agents with Vector Stores",description:"This notebook covers how to combine agents and vector stores. The use case for this is that you\u2019ve ingested your data into a vector store and want to interact with it in an agentic manner.",source:"@site/docs/modules/agents/tools/agents_with_vectorstores.md",sourceDirName:"modules/agents/tools",slug:"/modules/agents/tools/agents_with_vectorstores",permalink:"/langchainjs/docs/modules/agents/tools/agents_with_vectorstores",draft:!1,editUrl:"https://github.com/hwchase17/langchainjs/docs/modules/agents/tools/agents_with_vectorstores.md",tags:[],version:"current",frontMatter:{},sidebar:"sidebar",previous:{title:"Tools",permalink:"/langchainjs/docs/modules/agents/tools/"},next:{title:"ChatGPT Plugins",permalink:"/langchainjs/docs/modules/agents/tools/aiplugin-tool"}},c={},l=[],u={toc:l},p="wrapper";function h(t){let{components:e,...n}=t;return(0,r.kt)(p,(0,o.Z)({},u,n,{components:e,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"agents-with-vector-stores"},"Agents with Vector Stores"),(0,r.kt)("p",null,"This notebook covers how to combine agents and vector stores. The use case for this is that you\u2019ve ingested your data into a vector store and want to interact with it in an agentic manner."),(0,r.kt)("p",null,"The recommended method for doing so is to create a VectorDBQAChain and then use that as a tool in the overall agent. Let\u2019s take a look at doing this below. You can do this with multiple different vector databases, and use the agent as a way to choose between them. There are two different ways of doing this - you can either let the agent use the vector stores as normal tools, or you can set ",(0,r.kt)("inlineCode",{parentName:"p"},"returnDirect: true")," to just use the agent as a router."),(0,r.kt)("p",null,"First, you'll want to import the relevant modules:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-typescript"},'import { OpenAI } from "langchain";\nimport { initializeAgentExecutor } from "langchain/agents";\nimport { SerpAPI, Calculator, ChainTool } from "langchain/tools";\nimport { VectorDBQAChain } from "langchain/chains";\nimport { HNSWLib } from "langchain/vectorstores";\nimport { OpenAIEmbeddings } from "langchain/embeddings";\nimport { RecursiveCharacterTextSplitter } from "langchain/text_splitter";\nimport * as fs from "fs";\n')),(0,r.kt)("p",null,"Next, you'll want to create the vector store with your data, and then the QA chain to interact with that vector store."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-typescript"},'const model = new OpenAI({ temperature: 0 });\n/* Load in the file we want to do question answering over */\nconst text = fs.readFileSync("state_of_the_union.txt", "utf8");\n/* Split the text into chunks */\nconst textSplitter = new RecursiveCharacterTextSplitter({ chunkSize: 1000 });\nconst docs = await textSplitter.createDocuments([text]);\n/* Create the vectorstore */\nconst vectorStore = await HNSWLib.fromDocuments(docs, new OpenAIEmbeddings());\n/* Create the chain */\nconst chain = VectorDBQAChain.fromLLM(model, vectorStore);\n')),(0,r.kt)("p",null,"Now that you have that chain, you can create a tool to use that chain. Note that you should update the name and description to be specific to your QA chain."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-typescript"},'const qaTool = new ChainTool({\n  name: "state-of-union-qa",\n  description:\n    "State of the Union QA - useful for when you need to ask questions about the most recent state of the union address.",\n  chain: chain,\n});\n')),(0,r.kt)("p",null,"Now you can construct and using the tool just as you would any other!"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-typescript"},'const tools = [new SerpAPI(), new Calculator(), qaTool];\n\nconst executor = await initializeAgentExecutor(\n  tools,\n  model,\n  "zero-shot-react-description"\n);\nconsole.log("Loaded agent.");\n\nconst input = `What did biden say about ketanji brown jackson is the state of the union address?`;\n\nconsole.log(`Executing with input "${input}"...`);\n\nconst result = await executor.call({ input });\n\nconsole.log(`Got output ${result.output}`);\n')),(0,r.kt)("p",null,"You can also set ",(0,r.kt)("inlineCode",{parentName:"p"},"returnDirect: true")," if you intend to use the agent as a router and just want to directly return the result of the VectorDBQAChain."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-typescript"},'const qaTool = new ChainTool({\n  name: "state-of-union-qa",\n  description:\n    "State of the Union QA - useful for when you need to ask questions about the most recent state of the union address.",\n  chain: chain,\n  returnDirect: true,\n});\n')))}h.isMDXComponent=!0}}]);