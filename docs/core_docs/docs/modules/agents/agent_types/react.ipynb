{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReAct\n",
    "\n",
    "This walkthrough showcases using an agent to implement the [ReAct](https://react-lm.github.io/) logic.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Install the OpenAI integration package, retrieve your key, and store it as an environment variable named `OPENAI_API_KEY`:\n",
    "\n",
    ":::tip\n",
    "See [this section for general instructions on installing integration packages](/docs/get_started/installation#installing-integration-packages).\n",
    ":::\n",
    "\n",
    "```bash npm2yarn\n",
    "npm install @langchain/openai\n",
    "```\n",
    "\n",
    "This demo also uses [Tavily](https://app.tavily.com), but you can also swap in another [built in tool](/docs/integrations/platforms).\n",
    "You'll need to sign up for an API key and set it as `TAVILY_API_KEY`.\n",
    "\n",
    "## Initialize Tools\n",
    "\n",
    "We will first create a tool:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "No Tavily API key found. Either set an environment variable named \"TAVILY_API_KEY\" or pass an API key as \"apiKey\".",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "Error: No Tavily API key found. Either set an environment variable named \"TAVILY_API_KEY\" or pass an API key as \"apiKey\".",
      "    at new TavilySearchResults (file:///Users/bracesproul/code/lang-chain-ai/wt/brace/ipynb-docs/libs/langchain-community/dist/tools/tavily_search.js:46:19)",
      "    at <anonymous>:4:3"
     ]
    }
   ],
   "source": [
    "import { TavilySearchResults } from \"@langchain/community/tools/tavily_search\";\n",
    "\n",
    "// Define the tools the agent will have access to.\n",
    "const tools = [new TavilySearchResults({ maxResults: 1 })];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "loaded langchain/agents\n",
      "loaded langchain/hub\n",
      "loaded @langchain/openai\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "OpenAI or Azure OpenAI API key not found",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "Error: OpenAI or Azure OpenAI API key not found",
      "    at new OpenAI (file:///Users/bracesproul/code/lang-chain-ai/wt/brace/ipynb-docs/libs/langchain-openai/dist/llms.js:233:19)",
      "    at <anonymous>:12:13",
      "    at eventLoopTick (ext:core/01_core.js:181:11)"
     ]
    }
   ],
   "source": [
    "console.log(\"start\")\n",
    "import { createReactAgent } from \"langchain/agents\";\n",
    "console.log(\"loaded langchain/agents\")\n",
    "import { pull } from \"langchain/hub\";\n",
    "console.log(\"loaded langchain/hub\")\n",
    "import { OpenAI } from \"@langchain/openai\";\n",
    "console.log(\"loaded @langchain/openai\")\n",
    "import type { PromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "// Get the prompt to use - you can modify this!\n",
    "// If you want to see the prompt in full, you can at:\n",
    "// https://smith.langchain.com/hub/hwchase17/react\n",
    "const prompt = await pull<PromptTemplate>(\"hwchase17/react\");\n",
    "\n",
    "const llm = new OpenAI({\n",
    "  modelName: \"gpt-3.5-turbo-instruct\",\n",
    "  temperature: 0,\n",
    "});\n",
    "\n",
    "const agent = await createReactAgent({\n",
    "  llm,\n",
    "  tools,\n",
    "  prompt,\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Agent\n",
    "\n",
    "Now, let's run our agent!\n",
    "\n",
    ":::tip\n",
    "[LangSmith trace](https://smith.langchain.com/public/44989da5-8742-429f-9ab1-2377d773b0d2/r)\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const agentExecutor = new AgentExecutor({\n",
    "  agent,\n",
    "  tools,\n",
    "});\n",
    "\n",
    "await agentExecutor.invoke({\n",
    "  input: \"what is LangChain?\",\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using with chat history\n",
    "\n",
    "For more details, see [this section of the agent quickstart](/docs/modules/agents/quick_start#adding-in-memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ReferenceError",
     "evalue": "llm is not defined",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "ReferenceError: llm is not defined",
      "    at <anonymous>:6:3",
      "    at eventLoopTick (ext:core/01_core.js:181:11)"
     ]
    }
   ],
   "source": [
    "// Get the prompt to use - you can modify this!\n",
    "// If you want to see the prompt in full, you can at:\n",
    "// https://smith.langchain.com/hub/hwchase17/react-chat\n",
    "const promptWithChat = await pull<PromptTemplate>(\"hwchase17/react-chat\");\n",
    "\n",
    "const agentWithChat = await createReactAgent({\n",
    "  llm,\n",
    "  tools,\n",
    "  prompt: promptWithChat,\n",
    "});\n",
    "\n",
    "const agentExecutorWithChat = new AgentExecutor({\n",
    "  agent: agentWithChat,\n",
    "  tools,\n",
    "});\n",
    "\n",
    "await agentExecutorWithChat.invoke({\n",
    "  input: \"what's my name?\",\n",
    "  // Notice that chat_history is a string, since this prompt is aimed at LLMs, not chat models\n",
    "  chat_history: \"Human: Hi! My name is Cob\\nAI: Hello Cob! Nice to meet you\",\n",
    "});"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nb_converter": "script",
   "pygments_lexer": "typescript",
   "version": "5.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
