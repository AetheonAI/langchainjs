# Multi Modal Rag

:::info
The [GPT-4V model by OpenAI](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo#:~:text=to%20Apr%202023-,gpt%2D4%2Dvision%2Dpreview,-GPT%2D4%20Turbo) is still in preview
:::

This example will demonstrate how to preform [RAG](https://arxiv.org/abs/2005.11401) on images, using the new GPT-4V model by OpenAI.

At a high level we're:

- Passing all images to GPT-4V and summarizing their contents
- Embedding the summaries and adding links to the images in metadata
- Using semantic search on a query to retrieve the most relevant image
- Passing the full image and user query to GPT-4V for a final answer.

import CodeBlock from "@theme/CodeBlock";
import MultiModalRagExample from "@examples/use_cases/multi_modal/multi_modal_rag.ts";

<CodeBlock language="typescript">{MultiModalRagExample}</CodeBlock>
